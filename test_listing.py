#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime

def test_single_listing():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
    
    print("=" * 60)
    print("–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
    print("=" * 60)
    
    # –ß–∏—Ç–∞–µ–º URL –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
    except FileNotFoundError:
        with open('config.example.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π URL –¥–ª—è kleinanzeigen
    search_urls = config.get('search_urls', [])
    kleinanzeigen_url = None
    for url in search_urls:
        if 'kleinanzeigen.de' in url:
            kleinanzeigen_url = url
            break
    
    if not kleinanzeigen_url:
        print("‚ùå URL –¥–ª—è Kleinanzeigen –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥–µ")
        return
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7',
    })
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    print(f"\nüìç –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å: {kleinanzeigen_url}\n")
    response = session.get(kleinanzeigen_url, timeout=10)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # –ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    links = []
    for element in soup.select('article h2 a'):
        href = element.get('href')
        if href and '/s-anzeige/' in href:
            if not href.startswith('http'):
                href = 'https://www.kleinanzeigen.de' + href
            links.append(href)
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(links)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π\n")
    
    if not links:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
        return
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∞
    test_url = links[0]
    print(f"üîç –¢–µ—Å—Ç–∏—Ä—É—é –ø–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: {test_url}\n")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    try:
        response = session.get(test_url, timeout=10)
        print(f"   –°—Ç–∞—Ç—É—Å: {response.status_code}")
        print(f"   –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤\n")
        
        if response.status_code != 200:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ HTTP {response.status_code}")
            return
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:\n")
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_elem = soup.find('h1')
        title = title_elem.get_text(strip=True) if title_elem else None
        print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
        
        # –¶–µ–Ω–∞
        price = None
        price_selectors = [
            '.boxedarticle--price',
            '.aditem-main--middle--price-shipping--price',
            'h2:contains("‚Ç¨")',
            '.price-label'
        ]
        
        for selector in price_selectors:
            if ':contains(' in selector:
                price_elem = soup.find('h2', string=re.compile(r'‚Ç¨'))
            else:
                price_elem = soup.select_one(selector)
            
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                print(f"   –¶–µ–Ω–∞ (—Å–µ–ª–µ–∫—Ç–æ—Ä {selector}): {price_text}")
                price_match = re.search(r'(\d+(?:\.\d+)?)', price_text.replace('.', '').replace(',', ''))
                if price_match:
                    price = int(float(price_match.group(1)))
                break
        
        print(f"   –¶–µ–Ω–∞ (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è): {price}")
        
        # –î–∞—Ç–∞
        print("\n   üóìÔ∏è  –ü–æ–∏—Å–∫ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º #viewad-extra-info
        viewad_info = soup.select_one('#viewad-extra-info')
        if viewad_info:
            info_text = viewad_info.get_text()
            print(f"      #viewad-extra-info: {info_text[:200]}")
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{4})', info_text)
            if date_match:
                print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –¥–∞—Ç–∞: {date_match.group(1)}")
            else:
                print(f"      ‚ùå –î–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ #viewad-extra-info")
        else:
            print(f"      ‚ùå –≠–ª–µ–º–µ–Ω—Ç #viewad-extra-info –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –î—Ä—É–≥–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
        date_selectors = [
            '.aditem-details--top--right',
            '.aditem-addon',  
            '.ad-keyfacts',
            '.aditem-main--top--right'
        ]
        
        for selector in date_selectors:
            date_elem = soup.select_one(selector)
            if date_elem:
                date_text = date_elem.get_text(strip=True)
                print(f"      {selector}: {date_text[:100]}")
                date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{4})', date_text)
                if date_match:
                    print(f"         ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –¥–∞—Ç–∞: {date_match.group(1)}")
        
        # –†–∞–∑–º–µ—Ä –∏ –∫–æ–º–Ω–∞—Ç—ã
        print("\n   üè† –ü–æ–∏—Å–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫:")
        details_section = soup.find('dl') or soup.find('div', class_='addetailslist')
        if details_section:
            text = details_section.get_text()
            print(f"      –¢–µ–∫—Å—Ç –∏–∑ –¥–µ—Ç–∞–ª–µ–π: {text[:200]}")
            
            # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ HTML
            size = None
            rooms = None
            
            for item in details_section.find_all(['dt', 'li']):
                item_text = item.get_text().strip().lower()
                
                # –ü–æ–∏—Å–∫ —Ä–∞–∑–º–µ—Ä–∞
                if 'wohnfl√§che' in item_text or 'wohnflache' in item_text:
                    value_elem = item.find('span', class_='addetailslist--detail--value')
                    if value_elem:
                        value_text = value_elem.get_text().strip()
                        size_match = re.search(r'(\d+)', value_text)
                        if size_match:
                            size = int(size_match.group(1))
                            print(f"      ‚úÖ –ü–ª–æ—â–∞–¥—å (–∏–∑ span): {size} m¬≤")
                
                # –ü–æ–∏—Å–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–Ω–∞—Ç
                if 'zimmer' in item_text and 'schlafzimmer' not in item_text and 'badezimmer' not in item_text:
                    value_elem = item.find('span', class_='addetailslist--detail--value')
                    if value_elem:
                        value_text = value_elem.get_text().strip()
                        rooms_match = re.search(r'(\d+(?:[.,]\d+)?)', value_text)
                        if rooms_match:
                            rooms = rooms_match.group(1).replace(',', '.')
                            print(f"      ‚úÖ –ö–æ–º–Ω–∞—Ç—ã (–∏–∑ span): {rooms}")
            
            if not size:
                size_match = re.search(r'(\d+)\s*m¬≤', text)
                if size_match:
                    print(f"      ‚úÖ –ü–ª–æ—â–∞–¥—å: {size_match.group(1)} m¬≤")
                else:
                    print(f"      ‚ùå –ü–ª–æ—â–∞–¥—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            if not rooms:
                # –ë–æ–ª–µ–µ –≥–∏–±–∫–æ–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
                rooms_match = re.search(r'Zimmer\s+(\d+(?:[.,]\d+)?)', text, re.IGNORECASE)
                if not rooms_match:
                    rooms_match = re.search(r'(\d+(?:[.,]\d+)?)\s+Zimmer', text, re.IGNORECASE)
                if rooms_match:
                    print(f"      ‚úÖ –ö–æ–º–Ω–∞—Ç—ã (regex): {rooms_match.group(1)}")
                else:
                    print(f"      ‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        else:
            print(f"      ‚ùå –°–µ–∫—Ü–∏—è —Å –¥–µ—Ç–∞–ª—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML
        with open('/tmp/listing_page.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        print("\n   üíæ HTML –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ /tmp/listing_page.html")
        
        print("\n" + "=" * 60)
        print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω")
        print("=" * 60)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    test_single_listing()
