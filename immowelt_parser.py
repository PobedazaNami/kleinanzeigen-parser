#!/usr/bin/env python3
"""
Immowelt Parser –¥–ª—è –∫–≤–∞—Ä—Ç–∏—Ä –≤ –∞—Ä–µ–Ω–¥—É
–ü–∞—Ä—Å–∏—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å Immowelt.de –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Firecrawl API –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã –æ—Ç –±–æ—Ç–æ–≤
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import logging
import re
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from urllib.parse import urljoin
import hashlib

from base_parser import BaseParser

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å Firecrawl
try:
    from firecrawl import FirecrawlApp
    FIRECRAWL_AVAILABLE = True
except ImportError:
    FIRECRAWL_AVAILABLE = False


class ImmoweltParser(BaseParser):
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å Immowelt.de —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Firecrawl API"""
    
    def __init__(self, config_file: str = "config.json"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è Immowelt"""
        super().__init__(config_file, parser_name="immowelt")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Firecrawl
        self.firecrawl_api_key = os.getenv('FIRECRAWL_API_KEY')
        self.use_firecrawl = self.config.get('immowelt_settings', {}).get('use_firecrawl', True)
        
        if self.use_firecrawl and self.firecrawl_api_key and FIRECRAWL_AVAILABLE:
            try:
                self.firecrawl = FirecrawlApp(api_key=self.firecrawl_api_key)
                self.logger.info("‚úÖ Firecrawl API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Immowelt")
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Firecrawl: {e}")
                self.firecrawl = None
                self.use_firecrawl = False
        else:
            self.firecrawl = None
            if self.use_firecrawl and not self.firecrawl_api_key:
                self.logger.warning("‚ö†Ô∏è  FIRECRAWL_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ ENV")
                self.use_firecrawl = False
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é session –¥–ª—è Immowelt —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∏–º–∏—Ç–∞—Ü–∏–µ–π –±—Ä–∞—É–∑–µ—Ä–∞
        self.session = requests.Session()
        
        # –ë–æ–ª–µ–µ –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä headers –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'DNT': '1',
        })
        
        self.logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–∞—Ä—Å–µ—Ä –¥–ª—è Immowelt.de (Firecrawl: {'‚úÖ' if self.use_firecrawl else '‚ùå'})")
    
    def get_page_with_firecrawl(self, url: str) -> Optional[BeautifulSoup]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ Firecrawl API"""
        if not self.use_firecrawl or not self.firecrawl:
            return None
        
        try:
            self.logger.info(f"üî• –ó–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Firecrawl: {url}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º scrape –º–µ—Ç–æ–¥ Firecrawl (–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ API v2)
            result = self.firecrawl.scrape(
                url,
                formats=['html'],
                only_main_content=False,
                wait_for=2000  # –ñ–¥–µ–º 2 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ JavaScript
            )
            
            if result and hasattr(result, 'html') and result.html:
                html_content = result.html
                self.logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —á–µ—Ä–µ–∑ Firecrawl: {len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                return BeautifulSoup(html_content, 'html.parser')
            elif result and hasattr(result, 'markdown') and result.markdown:
                html_content = result.markdown
                self.logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —á–µ—Ä–µ–∑ Firecrawl (markdown): {len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                return BeautifulSoup(html_content, 'html.parser')
            else:
                self.logger.warning(f"‚ö†Ô∏è  Firecrawl –Ω–µ –≤–µ—Ä–Ω—É–ª HTML –¥–ª—è {url}")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ Firecrawl –¥–ª—è {url}: {e}")
            return None
    
    def get_page(self, url: str, retries: int = 3) -> Optional[BeautifulSoup]:
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Firecrawl"""
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º Firecrawl –¥–ª—è Immowelt
        if self.use_firecrawl and 'immowelt.de' in url:
            soup = self.get_page_with_firecrawl(url)
            if soup:
                return soup
            else:
                self.logger.warning("‚ö†Ô∏è  Firecrawl –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å...")
        
        # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π HTTP –∑–∞–ø—Ä–æ—Å
        return super().get_page(url, retries)
    
    def get_initial_cookies(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö cookies —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã Immowelt"""
        try:
            self.logger.info("–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö cookies –¥–ª—è Immowelt...")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            time.sleep(1)
            
            # –°–Ω–∞—á–∞–ª–∞ –∑–∞—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é
            response = self.session.get('https://www.immowelt.de/', timeout=30, allow_redirects=True)
            
            self.logger.debug(f"–°—Ç–∞—Ç—É—Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {response.status_code}")
            self.logger.debug(f"–ü–æ–ª—É—á–µ–Ω–æ cookies: {len(self.session.cookies)}")
            
            if response.status_code == 200:
                self.logger.info("Cookies –¥–ª—è Immowelt –ø–æ–ª—É—á–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º Referer –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                self.session.headers['Referer'] = 'https://www.immowelt.de/'
                return True
            else:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å cookies –¥–ª—è Immowelt: {response.status_code}")
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                self.logger.debug(f"Response text (first 500 chars): {response.text[:500]}")
                return False
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ cookies –¥–ª—è Immowelt: {e}")
            return False
    
    def extract_listing_links(self, soup: BeautifulSoup, base_url: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ —Å–ø–∏—Å–∫–∞ Immowelt (—Ç–æ–ª—å–∫–æ —Å –º–µ—Ç–∫–æ–π Neu)"""
        links = []
        
        # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–æ –∑–Ω–∞—á–∫–æ–º "Neu" - –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        neu_elements = soup.find_all('span', attrs={'data-testid': 'cardmfe-tag-testid-new'})
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ data-testid, –∏—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É
        if not neu_elements:
            neu_elements = soup.find_all('span', string=lambda x: x and x.strip() == 'Neu')
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(neu_elements)} –∑–Ω–∞—á–∫–æ–≤ 'Neu' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–Ω–∞—á–∫–∞ "Neu" –∏—â–µ–º –±–ª–∏–∂–∞–π—à—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
        for neu_span in neu_elements:
            # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –≤–≤–µ—Ä—Ö –ø–æ –¥–µ—Ä–µ–≤—É –¥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –∫–∞—Ä—Ç–æ—á–∫–∏
            container = neu_span
            for _ in range(20):  # –ú–∞–∫—Å–∏–º—É–º 20 —É—Ä–æ–≤–Ω–µ–π –≤–≤–µ—Ä—Ö
                if container is None:
                    break
                container = container.parent
                
                # –ò—â–µ–º —Å—Å—ã–ª–∫—É —Å /expose/ –≤ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
                if container:
                    link = container.find('a', href=lambda href: href and '/expose/' in href)
                    if link:
                        href = link.get('href')
                        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π URL
                        if href.startswith('http'):
                            full_url = href
                        elif href.startswith('/'):
                            full_url = 'https://www.immowelt.de' + href
                        else:
                            full_url = urljoin(base_url, href)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏
                        if full_url not in links:
                            links.append(full_url)
                            self.logger.debug(f"–ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ: {full_url}")
                        break
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(links)} –ù–û–í–´–• –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –º–µ—Ç–∫–æ–π 'Neu' –Ω–∞ Immowelt")
        return links
    
    def extract_listing_date(self, soup: BeautifulSoup) -> Optional[datetime]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å Immowelt"""
        try:
            today = datetime.now()
            
            # –ò—â–µ–º –¥–∞—Ç—É –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ Immowelt
            date_selectors = [
                'div[data-test="objectdata"] span',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –¥–∞—Ç—ã
                '.hardfact',  # –ñ–µ—Å—Ç–∫–∏–µ —Ñ–∞–∫—Ç—ã
                'sd-cell-col',  # –î–∞—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ
                '.objektdaten'  # –î–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞
            ]
            
            for selector in date_selectors:
                date_elems = soup.select(selector)
                for date_elem in date_elems:
                    date_text = date_elem.get_text()
                    self.logger.debug(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç: {date_text[:100]}")
                    
                    # –ò—â–µ–º —Ç–æ—á–Ω—É—é –¥–∞—Ç—É DD.MM.YYYY
                    date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{4})', date_text)
                    if date_match:
                        date_str = date_match.group(1)
                        try:
                            day, month, year = date_str.split('.')
                            parsed_date = datetime(int(year), int(month), int(day))
                            self.logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ –¥–∞—Ç–∞: {parsed_date.strftime('%d.%m.%Y')}")
                            return parsed_date
                        except ValueError:
                            continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã
                    lower_text = date_text.lower()
                    if any(word in lower_text for word in ['heute', 'today']):
                        self.logger.debug("–ù–∞–π–¥–µ–Ω 'Heute'")
                        return today
                    
                    if any(word in lower_text for word in ['gestern', 'yesterday']):
                        self.logger.debug("–ù–∞–π–¥–µ–Ω 'Gestern'")
                        return today - timedelta(days=1)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ "vor X Tagen"
                    days_ago_match = re.search(r'vor\s+(\d+)\s+tag', lower_text)
                    if days_ago_match:
                        days_ago = int(days_ago_match.group(1))
                        parsed_date = today - timedelta(days=days_ago)
                        self.logger.debug(f"–ù–∞–π–¥–µ–Ω–æ 'vor {days_ago} Tagen'")
                        return parsed_date
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –¥–∞—Ç—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
            self.logger.debug("–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ Immowelt")
            return None
            
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞—Ç—ã –∏–∑ Immowelt: {e}")
            return None
    
    def extract_listing_data(self, soup: BeautifulSoup, url: str) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è Immowelt"""
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            title_selectors = [
                'h1[data-test="expose-title"]',
                'h1.ng-binding',
                'h1',
                '.expose_header h1'
            ]
            
            title = "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            for selector in title_selectors:
                title_elem = soup.select_one(selector)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    break
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã
            price = None
            price_selectors = [
                'span.css-9wpf20',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è —Ü–µ–Ω—ã –Ω–∞ Immowelt
                'div[data-test="price"] strong',
                '.hardfact_value strong',
                'strong[data-test="kaltmiete"]',
                '.price_value'
            ]
            
            for selector in price_selectors:
                price_elem = soup.select_one(selector)
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, —Ç–æ—á–µ–∫ –∏ –∑–∞–ø—è—Ç—ã—Ö
                    price_text = re.sub(r'[^\d,.]', '', price_text)
                    
                    # –í –Ω–µ–º–µ—Ü–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ: 753.71 ‚Ç¨ = 753 –µ–≤—Ä–æ 71 —Ü–µ–Ω—Ç
                    # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ—á–∫—É –Ω–∞ –Ω–∏—á–µ–≥–æ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç—ã—Å—è—á), –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É (–¥–µ—Å—è—Ç–∏—á–Ω–∞—è —á–∞—Å—Ç—å)
                    if ',' in price_text:
                        # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø—è—Ç–∞—è, —ç—Ç–æ –¥–µ—Å—è—Ç–∏—á–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                        price_text = price_text.replace('.', '').replace(',', '.')
                    # –ï—Å–ª–∏ –Ω–µ—Ç –∑–∞–ø—è—Ç–æ–π, —Ç–æ—á–∫–∞ - —ç—Ç–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç—ã—Å—è—á –∏–ª–∏ –¥–µ—Å—è—Ç–∏—á–Ω—ã–π
                    elif '.' in price_text:
                        parts = price_text.split('.')
                        if len(parts) == 2 and len(parts[1]) == 2:
                            # 753.71 - —ç—Ç–æ 753 –µ–≤—Ä–æ —Å —Ü–µ–Ω—Ç–∞–º–∏
                            price_text = price_text  # –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        else:
                            # 1.000 - —ç—Ç–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç—ã—Å—è—á
                            price_text = price_text.replace('.', '')
                    
                    try:
                        price = int(float(price_text))
                        break
                    except ValueError:
                        continue
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–Ω–∞—Ç
            size = None
            rooms = None
            
            # –ü–æ–∏—Å–∫ –≤ hardfacts (–∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
            hardfacts = soup.select('div[data-test="hardfact"]')
            for fact in hardfacts:
                fact_text = fact.get_text()
                
                # –†–∞–∑–º–µ—Ä –∫–≤–∞—Ä—Ç–∏—Ä—ã
                if 'wohnfl√§che' in fact_text.lower() or 'm¬≤' in fact_text.lower():
                    size_match = re.search(r'(\d+(?:[.,]\d+)?)\s*m¬≤', fact_text)
                    if size_match:
                        size_str = size_match.group(1).replace(',', '.')
                        size = int(float(size_str))
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç
                if 'zimmer' in fact_text.lower():
                    rooms_match = re.search(r'(\d+(?:[.,]\d+)?)', fact_text)
                    if rooms_match:
                        rooms = rooms_match.group(1).replace(',', '.')
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not size or not rooms:
                cells = soup.select('sd-cell')
                for cell in cells:
                    cell_text = cell.get_text()
                    
                    if not size and ('wohnfl√§che' in cell_text.lower() or 'm¬≤' in cell_text.lower()):
                        size_match = re.search(r'(\d+(?:[.,]\d+)?)\s*m¬≤', cell_text)
                        if size_match:
                            size_str = size_match.group(1).replace(',', '.')
                            size = int(float(size_str))
                    
                    if not rooms and 'zimmer' in cell_text.lower():
                        rooms_match = re.search(r'(\d+(?:[.,]\d+)?)', cell_text)
                        if rooms_match:
                            rooms = rooms_match.group(1).replace(',', '.')
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª–æ–∫–∞—Ü–∏–∏
            location = None
            location_selectors = [
                'span.css-wpv6zq',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –∞–¥—Ä–µ—Å–∞ –Ω–∞ Immowelt
                'div[data-test="address"]',
                'span.location',
                '.expose_header .address',
                'p.address'
            ]
            
            for selector in location_selectors:
                location_elem = soup.select_one(selector)
                if location_elem:
                    location = location_elem.get_text(strip=True)
                    break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
            if not location:
                location_match = re.search(r'\d{5}\s+[A-Za-z√Ñ√ñ√ú√§√∂√º√ü\s-]+', soup.get_text())
                if location_match:
                    location = location_match.group().strip()
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è
            description_selectors = [
                'div[data-test="description-text"]',
                'div.freitext',
                'pre#objectDescription',
                'div.beschreibung'
            ]
            
            description = ""
            for selector in description_selectors:
                description_elem = soup.select_one(selector)
                if description_elem:
                    description = description_elem.get_text(strip=True)
                    break
            
            # –î–ª—è Immowelt –¥–∞—Ç–∞ –Ω–µ –Ω—É–∂–Ω–∞ - –º—ã —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∑–Ω–∞—á–∫—É "Neu"
            # –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —É–∂–µ –Ω–æ–≤—ã–µ, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∞—Ç—É
            listing_date = datetime.now()
            self.logger.debug("–î–ª—è Immowelt –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É (—Ñ–∏–ª—å—Ç—Ä –ø–æ –∑–Ω–∞—á–∫—É Neu)")
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ URL
            listing_id_match = re.search(r'/expose/(\d+)', url)
            if listing_id_match:
                listing_id = 'immowelt_' + listing_id_match.group(1)
            else:
                listing_id = 'immowelt_' + hashlib.md5(url.encode()).hexdigest()[:10]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ö—ç—à–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            hash_string = f"{title}_{price}_{size}_{location}"
            listing_hash = hashlib.md5(hash_string.encode('utf-8')).hexdigest()
            
            listing_data = {
                'id': listing_id,
                'title': title,
                'price': price,
                'size': size,
                'rooms': rooms,
                'location': location,
                'description': description[:500] if description else "",
                'url': url,
                'date_posted': listing_date.isoformat() if listing_date else None,
                'date_found': datetime.now().isoformat(),
                'hash': listing_hash
            }
            
            self.logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ Immowelt (NEW): {title} - {price}‚Ç¨ - {location}")
            return listing_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Immowelt {url}: {e}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return None

    def parse_listings(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª—è Immowelt"""
        # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º max_listings_per_run –¥–ª—è Immowelt
        original_max = self.config.get('settings', {}).get('max_listings_per_run', 50)
        immowelt_max = self.config.get('settings', {}).get('max_listings_immowelt', 2)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è Immowelt
        self.config['settings']['max_listings_per_run'] = immowelt_max
        self.logger.info(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è Immowelt: –º–∞–∫—Å–∏–º—É–º {immowelt_max} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        try:
            # –í—ã–∑—ã–≤–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –º–µ—Ç–æ–¥
            result = super().parse_listings()
            return result
        finally:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            self.config['settings']['max_listings_per_run'] = original_max


if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
    parser = ImmoweltParser()
    parser.parse_listings()
